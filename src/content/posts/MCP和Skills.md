---
title: 大模型开发入门
published: 2026-01-21
description: ''
image: ''
tags: ['学习','大模型应用']
category: '大模型'
draft: false 
lang: ''
---

> 本文章为笔者在学习时自行整理，如有侵权，请联系笔者删除。

## 目录
1. [基础概念](#1-基础概念)
2. [日常开发命令](#2-日常开发命令)
3. [分支管理策略](#3-分支管理策略)
4. [团队协作工作流](#4-团队协作工作流)
5. [代码审查 (Code Review)](#5-代码审查-code-review)
6. [冲突解决](#6-冲突解决)
7. [高级操作](#7-高级操作)
8. [Git Hooks 与自动化](#8-git-hooks-与自动化)
9. [大仓库 (Monorepo) 技巧](#9-大仓库-monorepo-技巧)
10. [故障排查与恢复](#10-故障排查与恢复)
11. [最佳实践](#11-最佳实践)
12. [面试高频问题](#12-面试高频问题)

## 一、基础概念
### 1.1 Vibe Coding
Vibe Coding:用自然语言+快速迭代，把写代码变成“边想边试边改”的创作过程。

区别在于:
1. 以前“跟着感觉写”容易卡在：
    - 不知道某个 API 怎么写
    - 框架配置太繁琐
    - 写样板代码很费时间
    - 报错难查，调半天
2. 大模型出现后：
    - 你一句话就能生成一段可跑的代码/配置
    - 报错贴进去能快速定位和给修复建议
    - 能随时重构、补测试、补类型
    - 让“试一个想法”从半天变成几分钟

Vibe Coding 在大模型时代的典型流程
1. 你说一句目标：
“给我做一个登录 + JWT 刷新 + Redis 黑名单”
2. AI 给你一个能跑的版本
3. 你运行，看到报错/不符合预期
4. 把报错贴回去，AI 给补丁
5. 一轮轮迭代直到可用
6. 最后再补：测试、异常处理、结构优化、文档

它的最大风险：
1. 代码“能跑但不对”：逻辑漏洞、边界没覆盖、性能/安全问题
2. 架构漂移：越改越乱，最后难维护
3. 复制粘贴幻觉：AI 可能编造 API/配置，或者给出“看似对”的错误实现

最实用的建议:
1. 先定接口/数据结构（别让核心对象一会儿一个样）
2. 关键路径必须有测试（登录/支付/权限这种）
3. 每完成一段就重构（把临时代码收拾干净）
4. 安全默认从严（token、权限、SQL、文件操作）

Vibe Coding的茁壮成长离不开主流大模型厂商的配套工具（CLI，IDE插件，编辑器）。
- openai： codex，可以云端、cli、vscode 插件
- Claude： Claude code 也就是 cc; cowork; 基本市面上的模型都可以接入 cc; 当然也有
vscode 插件
- gemini：geminicli；也有 vscode 插件，还有自己的 IDE “antigravity”可以看成 vscode 的套壳。定制版本。
国内的： kimi cli、 glmcode、 qwencoder 都可以用
还有[“AlonUi”自来水](https://github.com/iOfficeAI/AionUi)。

### 1.2 MCP和Skill
MCP，定义为是给 AI 使用的工具。
skill直译技能，定义为给 AI 使用的技能。


我骑车去图书馆，骑车就是我的技能，那么这个骑车的技能就是skill，骑车过去，那么我骑的这辆车，自行车这个工具它就是mcp

技能这个词在中文里的定义是：个体通过学习、训练或反复实践，逐步掌握并能熟练运用的，完成某项具体任务或活动的操作方式、动作系统或行为模式。

AI不需要反复实践，跑一次，就可以把它写成技能，可以理解为只要是这个 AI 干过的活，想让这个活让它重复的去干，就把它做成技能就好了。

不懂原理，该怎么搭建自己的配置，万能方法就是，mcp，你就看你能不能用得上，你能用得上，然后你把它这个链接直接扔给 AI，告诉他你帮我安装就好了；skill也是， [万能的skill创建教程和hooks创建教程 - 开发调优 - LINUX DO](https://linux.do/t/topic/1467359)。

### 1.3 LangChain


### 1.4 Dify
Dify 是一个用来快速搭建/上线大模型应用（LLM Apps的平台（开源 + 也有 SaaS 版本）。它把很多“做 AI 应用必须的东西”打包好了：可视化工作流、RAG 知识库、Agent 能力、模型接入管理、监控与日志等，让你从原型到生产更快。

你可以把它理解成：“大模型应用的低代码平台 / 工作流编排器”。

它主要能做什么
- 搭聊天机器人/企业助手：配置提示词、对话逻辑、工具调用
- 做 RAG（知识库问答）：把文档接入成知识库，让模型检索后再回答
- 做工作流自动化：用可视化画布把“多个步骤（LLM、条件判断、工具、HTTP 调用等）”串起来
- 接各种模型与推理后端：比如 OpenAI、Claude、以及一些本地/自建推理后端（如 vLLM）

典型组件（用 Dify 的人最常用的几个点）
- Workflow / Agentic workflow：可视化流程节点，把 LLM 变成“能执行步骤的智能体”
- RAG pipeline：文档切分、向量检索、引用上下文组织（让回答更“有依据”）
- 可观测性/运维：上线后看调用、日志、效果（平台通常会提供这类能力）

什么时候适合用 Dify
- 你想快速搭一个可用的 AI 应用（客服/问答/内部助手/自动化流程）
- 不想从零搭：向量库、检索、工作流、模型接入、权限、日志这些“工程底座”
- 需要团队一起配置和迭代（产品/运营也能上手一部分）

### 1.5 低代码平台
低代码平台（Low-code Platform）就是一种用“拖拽 + 配置”为主、少量写代码为辅来开发软件的工具/平台。目标是：更快做出业务应用，减少从零写代码的工作量。

它解决的核心问题

业务系统很多是“表单 + 流程 + 权限 + 报表 + 列表 + 审批”这类重复劳动

低代码把这些通用能力做成组件和模板，让你不用从头搭框架、写 CRUD

## 二、MCP(Model Context Protocol)
模型上下文协议是一个开放标准协议，其标准化了大语言模型(LLM)与外部世界的互动方式。MCP提供了一种标准化方法，使大模型语言能够轻松连接各种数据源和工具，实现信息的无缝访问和处理。MCP就像一个接口，为LLM提供了连接各种数据源的标准化方式。

![MCP协议](./image/LLM/MCP协议.png)

### 2.1 MCP解决的问题和价值
![MCP解决的问题](./image/LLM/MCP解决的问题.png)
价值在于:
- **标准化**: 统一的通信协议，降低集成成本
- **可扩展**: 模块化设计，轻松添加新能力
- **安全性**: 内置权限控制和审计机制
- **开源**: 社区驱动，大厂背书
### 2.2 核心架构
#### 2.2.1 三大组件
![MCP核心架构](./image/LLM/MCP核心架构.png)

#### 2.2.2 MCP核心原语
![系统核心原语](./image/LLM/系统核心原语.png)

#### 2.2.3 MCP流程
![MCP流程](./image/LLM/MCP流程.png)

